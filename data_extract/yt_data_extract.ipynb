{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install imageio==2.4.1\n",
        "!pip install youtube_comment_downloader"
      ],
      "metadata": {
        "id": "-2OViL5kSbMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-qh2wTLSIHQ"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube, extract\n",
        "from pytube.cli import on_progress\n",
        "from moviepy.editor import *\n",
        "import os, uuid, cv2, pandas as pd\n",
        "from itertools import islice\n",
        "from youtube_comment_downloader import *\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "metadata": {
        "id": "Zmq4DwiOYmFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('drive/MyDrive')\n",
        "\n",
        "if not os.path.exists('scomp_project'):\n",
        "    os.mkdir('scomp_project')\n",
        "    printmd(\"**A folder called scomp_project has been made for you, Please insert the video data csv file into it and rename it to video_data_url.csv**\")\n",
        "\n",
        "os.chdir('scomp_project')"
      ],
      "metadata": {
        "id": "QKqMC_liU-v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_header(path, headers):\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "\n",
        "        with open(path, 'a', encoding=\"utf-8\", newline='') as f_object:\n",
        "                        \n",
        "            dictwriter_object = DictWriter(f_object, fieldnames=headers)\n",
        "            dictwriter_object.writeheader()\n",
        "            f_object.close()"
      ],
      "metadata": {
        "id": "r47UekryHZfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createfolder(path):\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)"
      ],
      "metadata": {
        "id": "vWR9xhBOHbHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_comments(link):\n",
        "\n",
        "    comments = []\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            downloader = YoutubeCommentDownloader()\n",
        "            comments_list = []\n",
        "            comments = downloader.get_comments_from_url(link, sort_by=SORT_BY_POPULAR)\n",
        "            break\n",
        "        \n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    for comment in islice(comments, 10):\n",
        "        comments_list.append(comment['text'])\n",
        "    \n",
        "    return comments_list"
      ],
      "metadata": {
        "id": "c3wm1Y0rSM_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DownloadYoutube(link, id, video_data):\n",
        "    \n",
        "    youtubeObject = YouTube(link, on_progress_callback=on_progress)\n",
        "\n",
        "    video_data['id'] = id\n",
        "    video_data['title'] = youtubeObject.title\n",
        "    video_data['description'] = youtubeObject.description\n",
        "    video_data['comments'] = fetch_comments(link)\n",
        "\n",
        "    youtubeObject = youtubeObject.streams.get_highest_resolution()\n",
        "\n",
        "    name = str(uuid.uuid4()) + '.mp4'\n",
        "    youtubeObject.download(output_path='videos',filename=name)\n",
        "    print(\"Download is completed successfully\")\n",
        "\n",
        "    return name, video_data"
      ],
      "metadata": {
        "id": "jH2oQa5CTJlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_seconds(time):\n",
        "\n",
        "    time_div = time.split(':')\n",
        "    m_arr = [1,60,60*60]\n",
        "    seconds = 0\n",
        "\n",
        "    for count, time in enumerate(reversed(time_div)):\n",
        "        seconds += int(time)*m_arr[count]    \n",
        "\n",
        "    return seconds"
      ],
      "metadata": {
        "id": "IVnHbRziTOGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_images(path, new_filename ,img_nos):\n",
        "\n",
        "    cam = cv2.VideoCapture(path+new_filename+\".mp4\")\n",
        "    totframe = 0\n",
        "  \n",
        "    while(True):\n",
        "      \n",
        "        ret, frame = cam.read()\n",
        "        if ret: totframe += 1\n",
        "        else: break\n",
        "\n",
        "    cam.release()\n",
        "    cam = cv2.VideoCapture(path+new_filename+\".mp4\")\n",
        "\n",
        "    curr_frame = 0\n",
        "    capt_inc = int(totframe/(img_nos+1))\n",
        "    capt_pnt = int(totframe/(img_nos+1))\n",
        "    orig_img_nos = img_nos\n",
        "\n",
        "    createfolder(path+'images')\n",
        "\n",
        "    while img_nos != 0:\n",
        "      \n",
        "        ret, frame = cam.read()\n",
        "        if ret:\n",
        "\n",
        "            if curr_frame == capt_pnt:\n",
        "                \n",
        "                name = path+'images/'+new_filename+'_img'+ str(img_nos) + '.jpg'\n",
        "                cv2.imwrite(name, frame)\n",
        "                capt_pnt += capt_inc\n",
        "                img_nos -= 1\n",
        "                \n",
        "            curr_frame += 1\n",
        "\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    cam.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print('Collected '+str(orig_img_nos)+' images from video\\n\\n')"
      ],
      "metadata": {
        "id": "mnD7nnz3TPT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_out_video(filename, timefetch, emotion, id, index):\n",
        "\n",
        "    timelimits = timefetch.split('-')\n",
        "    start_time = timelimits[0].strip()\n",
        "    end_time = timelimits[1].strip()\n",
        "            \n",
        "    start_time = convert_to_seconds(start_time)\n",
        "    end_time = convert_to_seconds(end_time)\n",
        "            \n",
        "    video = VideoFileClip('videos/'+filename).subclip(start_time, end_time)\n",
        "\n",
        "    createfolder('cropped_videos/'+emotion)\n",
        "            \n",
        "    new_filename = str(uuid.uuid4())+'('+id+')'\n",
        "    video.write_videofile('cropped_videos/'+emotion+'/'+new_filename+ '.mp4') \n",
        "    video.close()\n",
        "    \n",
        "    print('Video '+str(index)+' downloaded')\n",
        "\n",
        "    collect_images('cropped_videos/'+emotion+'/', new_filename, 6)"
      ],
      "metadata": {
        "id": "kAKQPFHYTTbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    df = pd.read_csv('video_data_url.csv')\n",
        "\n",
        "    field_names_post = ['id','title','description','comments']\n",
        "    field_names_fail = ['Emotion', 'Url', 'Timestamp']\n",
        "\n",
        "    link_y_map = {}\n",
        "\n",
        "    createfolder('videos')\n",
        "    createfolder('cropped_videos')\n",
        "\n",
        "    insert_header('cropped_videos/posts_data.csv', field_names_post)\n",
        "    insert_header('cropped_videos/failed_data.csv', field_names_fail)\n",
        "\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        \n",
        "        link = row['Url']\n",
        "        emotion = row['Emotion']\n",
        "        timestamp = row['Timestamp']\n",
        "\n",
        "        id = extract.video_id(link)\n",
        "\n",
        "        try:\n",
        "            new_video = 0\n",
        "            filename = ''\n",
        "\n",
        "            if id in link_y_map:\n",
        "                filename = link_y_map[id]\n",
        "            else:\n",
        "                video_data = {}\n",
        "                filename, video_data = DownloadYoutube(link, id, video_data)\n",
        "                link_y_map[id] = filename\n",
        "                new_video = 1\n",
        "\n",
        "            if len(filename)>0:\n",
        "                crop_out_video(filename, timestamp, emotion, id, index)\n",
        "\n",
        "            if new_video:\n",
        "\n",
        "                with open('cropped_videos/posts_data.csv', 'a', encoding=\"utf-8\", newline='') as f_object:\n",
        "                        \n",
        "                    dictwriter_object = DictWriter(f_object, fieldnames=field_names_post)\n",
        "                    dictwriter_object.writerow(video_data)\n",
        "                    f_object.close()\n",
        "                    \n",
        "        except:\n",
        "            \n",
        "            print('!!!  Unable to process video no ' +str(index)+'  !!!')\n",
        "            print('Copying information of the data to failed_data.csv\\n\\n')\n",
        "\n",
        "            with open('cropped_videos/failed_data.csv', 'a', encoding=\"utf-8\", newline='') as f_object:\n",
        "                \n",
        "                dictwriter_object = DictWriter(f_object, fieldnames=field_names_fail)\n",
        "                dictwriter_object.writerow(row.to_dict())\n",
        "                f_object.close()"
      ],
      "metadata": {
        "id": "FZESqXw1TVl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}