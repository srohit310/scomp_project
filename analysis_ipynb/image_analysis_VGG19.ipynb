{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e7zUKNtYM5TG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "import os, pandas as pd, cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_zeKRadUuXF0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHjCbQqlsyu3",
        "outputId": "806f7685-fce7-4b00-a41f-5c4ee24d4e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2uJp4OqwK1M"
      },
      "outputs": [],
      "source": [
        "!unzip \"drive/My Drive/affectnethq.zip\" -d \"/content/affectnet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-Pftnp9XAyzw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('affectnet/labels.csv')\n",
        "df['label'] = df['label'].str.lower()\n",
        "\n",
        "df['pth'] = 'affectnet/' + df['pth'].astype(str)\n",
        "labels = df['label'].unique()\n",
        "lbl_cnt = df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Dataset processing using file commands </h2>"
      ],
      "metadata": {
        "id": "2pM2iFhwBxDp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IMXuMey0kiro"
      },
      "outputs": [],
      "source": [
        "train_split = 80\n",
        "valid_split = 20\n",
        "curr_lbl_cnt = {}\n",
        "emotion_set = {'anger', 'fear', 'happy', 'sad', 'surprise', 'neutral'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QzeT7usXzhif"
      },
      "outputs": [],
      "source": [
        "shutil.rmtree('proper_affectnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6yxO2rfFknep"
      },
      "outputs": [],
      "source": [
        "path = '/content/proper_affectnet'\n",
        "\n",
        "os.mkdir(path)\n",
        "os.mkdir(path+'/train')\n",
        "os.mkdir(path+'/valid')\n",
        "os.mkdir(path+'/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j1vQhLh5Huf"
      },
      "outputs": [],
      "source": [
        "for emotion in os.listdir('affectnet'):\n",
        "\n",
        "    if emotion not in emotion_set:\n",
        "        continue\n",
        "\n",
        "    tot_count = 3400\n",
        "    curr_count = 0\n",
        "\n",
        "    for file_name in os.listdir('affectnet/'+emotion):\n",
        "\n",
        "        ori_path = 'affectnet/'+emotion+'/'+file_name\n",
        "\n",
        "        if(curr_count < int((tot_count*train_split)/100)):\n",
        "        \n",
        "            if not os.path.exists(path+'/train/'+emotion):\n",
        "                os.mkdir(path+'/train/'+emotion)\n",
        "\n",
        "            shutil.copy(ori_path, path+'/train/'+emotion+'/')\n",
        "        \n",
        "        elif(curr_count < int((tot_count*(train_split+valid_split))/100)):\n",
        "\n",
        "            if not os.path.exists(path+'/valid/'+emotion):\n",
        "                os.mkdir(path+'/valid/'+emotion)\n",
        "\n",
        "            shutil.copy(ori_path, path+'/valid/'+emotion+'/')\n",
        "        \n",
        "        elif(curr_count < tot_count):\n",
        "\n",
        "            if not os.path.exists(path+'/test/'+emotion):\n",
        "                os.mkdir(path+'/test/'+emotion)\n",
        "\n",
        "            shutil.copy(ori_path, path+'/test/'+emotion+'/')\n",
        "        \n",
        "        else: break\n",
        "\n",
        "        curr_count += 1\n",
        "\n",
        "        print('pasted img no '+str(curr_count) +' of emotion '+emotion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgX7hO6-1hPL",
        "outputId": "e06d3611-0343-4b71-9a8c-f00d32bf67fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fear 3622\n",
            "neutral 5132\n",
            "surprise 4296\n",
            "contempt 3179\n",
            "sad 3430\n",
            "disgust 2660\n",
            "happy 5045\n",
            "anger 3638\n"
          ]
        }
      ],
      "source": [
        "for directory in os.listdir('affectnet'):\n",
        "\n",
        "    if 'labels' not in directory:\n",
        "        print(directory, len(os.listdir('affectnet/'+directory)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "UNkYi_JWBZD7"
      },
      "outputs": [],
      "source": [
        "train_dir = path+'/train'\n",
        "test_dir = path+'/test'\n",
        "val_dir = path+'/valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2eQCXnem4Wm",
        "outputId": "30578c11-89e8-45cd-ee7c-63dd213d60dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16320 images belonging to 6 classes.\n",
            "Found 4080 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=32)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=32)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     directory=test_dir,\n",
        "#     target_size=(224,224),\n",
        "#     class_mode='categorical',\n",
        "#     batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Dataset processing using dataframe</h2>"
      ],
      "metadata": {
        "id": "qgAVHAfiB7pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df , test_size = 0.2 , stratify = df['label'] , random_state = 0)"
      ],
      "metadata": {
        "id": "GPi2StXEBnOq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F083O9rrDf2k",
        "outputId": "65f3c8c4-ae26-451c-aa50-57fd198bd1e2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "surprise    3911\n",
              "happy       3505\n",
              "anger       3328\n",
              "disgust     3021\n",
              "fear        3002\n",
              "contempt    2870\n",
              "sad         2682\n",
              "neutral     2482\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    x_col = \"pth\",\n",
        "    y_col = \"label\",\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=32)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    x_col = \"pth\",\n",
        "    y_col = \"label\",\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "id": "ipHXyJLeLv0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Creating the Model</h2> "
      ],
      "metadata": {
        "id": "DrnETiRYLjo-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "6X0j2TYnNDDP"
      },
      "outputs": [],
      "source": [
        "pre_model = VGG19(weights='imagenet', \n",
        "                  input_shape=(224,224,3), \n",
        "                  include_top=False\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "yk6IIshUhqb3"
      },
      "outputs": [],
      "source": [
        "for layer in pre_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBKHx5cY1fZK",
        "outputId": "3e1001c5-0ec1-47b0-d66e-b65917a63508"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7fee48159f70> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee48263b80> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee4b1b83a0> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fee482bf190> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee4b510be0> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee4b56ec10> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fee482bf250> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee48162f40> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee4813fa30> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d328b0> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d38640> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fee48162a90> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d32e80> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d309a0> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d38d90> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fee4813f910> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fee4813f640> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d3bb80> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d45c70> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d45b20> False\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fef51d4cb50> False\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fef51d528e0> False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Kh9iDxXP8B",
        "outputId": "e45fde9a-4506-4001-a167-66b84032a605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 25088)            100352    \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,975,430\n",
            "Trainable params: 12,899,846\n",
            "Non-trainable params: 20,075,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    pre_model,\n",
        "    Dropout(0.3),\n",
        "    Flatten(),\n",
        "    Dense(8192, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(1024, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(6 , activation='softmax')])\n",
        "\n",
        "model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Dmyx2MWxZGPV"
      },
      "outputs": [],
      "source": [
        "model_name = 'emotion_vgg19_custom.h5'\n",
        "checkpointer = ModelCheckpoint(model_name, verbose=1, save_best_only=True)\n",
        "early_stopper = EarlyStopping(patience = 11, monitor='val_loss')\n",
        "\n",
        "callbacks = [checkpointer, early_stopper]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "sJXXLrU4ZkD1"
      },
      "outputs": [],
      "source": [
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13ini5S0ZorK",
        "outputId": "963ab228-2cbb-4376-9189-1d902ec00c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.0456 - accuracy: 0.3292\n",
            "Epoch 1: val_loss improved from inf to 2.99464, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 14s 865ms/step - loss: 3.0456 - accuracy: 0.3292 - val_loss: 2.9946 - val_accuracy: 0.3047\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.6461 - accuracy: 0.3729\n",
            "Epoch 2: val_loss improved from 2.99464 to 1.58053, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 12s 839ms/step - loss: 2.6461 - accuracy: 0.3729 - val_loss: 1.5805 - val_accuracy: 0.4922\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1258 - accuracy: 0.4396\n",
            "Epoch 3: val_loss improved from 1.58053 to 1.47375, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 13s 875ms/step - loss: 2.1258 - accuracy: 0.4396 - val_loss: 1.4737 - val_accuracy: 0.4609\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.9237 - accuracy: 0.4938\n",
            "Epoch 4: val_loss improved from 1.47375 to 1.32484, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 14s 875ms/step - loss: 1.9237 - accuracy: 0.4938 - val_loss: 1.3248 - val_accuracy: 0.4688\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.8308 - accuracy: 0.4812\n",
            "Epoch 5: val_loss improved from 1.32484 to 1.28283, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 13s 865ms/step - loss: 1.8308 - accuracy: 0.4812 - val_loss: 1.2828 - val_accuracy: 0.5234\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5637 - accuracy: 0.5250\n",
            "Epoch 6: val_loss did not improve from 1.28283\n",
            "15/15 [==============================] - 12s 811ms/step - loss: 1.5637 - accuracy: 0.5250 - val_loss: 1.3817 - val_accuracy: 0.5625\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4911 - accuracy: 0.5271\n",
            "Epoch 7: val_loss improved from 1.28283 to 1.21621, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 12s 821ms/step - loss: 1.4911 - accuracy: 0.5271 - val_loss: 1.2162 - val_accuracy: 0.5938\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4356 - accuracy: 0.5417\n",
            "Epoch 8: val_loss did not improve from 1.21621\n",
            "15/15 [==============================] - 13s 864ms/step - loss: 1.4356 - accuracy: 0.5417 - val_loss: 1.2351 - val_accuracy: 0.5469\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3269 - accuracy: 0.5396\n",
            "Epoch 9: val_loss improved from 1.21621 to 1.03209, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 12s 829ms/step - loss: 1.3269 - accuracy: 0.5396 - val_loss: 1.0321 - val_accuracy: 0.5859\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2064 - accuracy: 0.5917\n",
            "Epoch 10: val_loss did not improve from 1.03209\n",
            "15/15 [==============================] - 12s 804ms/step - loss: 1.2064 - accuracy: 0.5917 - val_loss: 1.1774 - val_accuracy: 0.5234\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2797 - accuracy: 0.5229\n",
            "Epoch 11: val_loss did not improve from 1.03209\n",
            "15/15 [==============================] - 12s 783ms/step - loss: 1.2797 - accuracy: 0.5229 - val_loss: 1.1332 - val_accuracy: 0.5391\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2088 - accuracy: 0.5917\n",
            "Epoch 12: val_loss did not improve from 1.03209\n",
            "15/15 [==============================] - 12s 790ms/step - loss: 1.2088 - accuracy: 0.5917 - val_loss: 1.1175 - val_accuracy: 0.5234\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1820 - accuracy: 0.6125\n",
            "Epoch 13: val_loss did not improve from 1.03209\n",
            "15/15 [==============================] - 12s 784ms/step - loss: 1.1820 - accuracy: 0.6125 - val_loss: 1.1364 - val_accuracy: 0.5312\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3227 - accuracy: 0.5583\n",
            "Epoch 14: val_loss did not improve from 1.03209\n",
            "15/15 [==============================] - 12s 770ms/step - loss: 1.3227 - accuracy: 0.5583 - val_loss: 1.1148 - val_accuracy: 0.5078\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2826 - accuracy: 0.5604\n",
            "Epoch 15: val_loss improved from 1.03209 to 1.02127, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 13s 846ms/step - loss: 1.2826 - accuracy: 0.5604 - val_loss: 1.0213 - val_accuracy: 0.5312\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5646\n",
            "Epoch 16: val_loss improved from 1.02127 to 0.88096, saving model to emotion_vgg19_custom.h5\n",
            "15/15 [==============================] - 13s 882ms/step - loss: 1.2109 - accuracy: 0.5646 - val_loss: 0.8810 - val_accuracy: 0.5703\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1022 - accuracy: 0.5979\n",
            "Epoch 17: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 810ms/step - loss: 1.1022 - accuracy: 0.5979 - val_loss: 1.1366 - val_accuracy: 0.5469\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1292 - accuracy: 0.6021\n",
            "Epoch 18: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 787ms/step - loss: 1.1292 - accuracy: 0.6021 - val_loss: 1.1727 - val_accuracy: 0.5312\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1022 - accuracy: 0.6000\n",
            "Epoch 19: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 763ms/step - loss: 1.1022 - accuracy: 0.6000 - val_loss: 0.9349 - val_accuracy: 0.6016\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0509 - accuracy: 0.5917\n",
            "Epoch 20: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 11s 762ms/step - loss: 1.0509 - accuracy: 0.5917 - val_loss: 1.1063 - val_accuracy: 0.5938\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1717 - accuracy: 0.5938\n",
            "Epoch 21: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 783ms/step - loss: 1.1717 - accuracy: 0.5938 - val_loss: 1.0987 - val_accuracy: 0.5547\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9995 - accuracy: 0.6083\n",
            "Epoch 22: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 795ms/step - loss: 0.9995 - accuracy: 0.6083 - val_loss: 1.0382 - val_accuracy: 0.6016\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0887 - accuracy: 0.5875\n",
            "Epoch 23: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 789ms/step - loss: 1.0887 - accuracy: 0.5875 - val_loss: 1.0854 - val_accuracy: 0.5859\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0173 - accuracy: 0.5958\n",
            "Epoch 24: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 816ms/step - loss: 1.0173 - accuracy: 0.5958 - val_loss: 0.9098 - val_accuracy: 0.6172\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9276 - accuracy: 0.6542\n",
            "Epoch 25: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 774ms/step - loss: 0.9276 - accuracy: 0.6542 - val_loss: 1.0366 - val_accuracy: 0.5781\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9773 - accuracy: 0.6125\n",
            "Epoch 26: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 775ms/step - loss: 0.9773 - accuracy: 0.6125 - val_loss: 1.1809 - val_accuracy: 0.5312\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9828 - accuracy: 0.6292\n",
            "Epoch 27: val_loss did not improve from 0.88096\n",
            "15/15 [==============================] - 12s 803ms/step - loss: 0.9828 - accuracy: 0.6292 - val_loss: 1.2351 - val_accuracy: 0.5391\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    steps_per_epoch=len(train_generator)//32,\n",
        "    epochs=epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator)//32,\n",
        "    verbose = 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}